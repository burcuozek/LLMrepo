# Large Language Models


Large Language Models (LLMs) are advanced artificial intelligence systems designed to process and generate human-like text based on vast amounts of training data. They employ deep learning techniques, particularly transformer architectures, to understand and produce language with high proficiency. LLMs have applications in natural language processing tasks such as translation, text generation, sentiment analysis, and question answering, revolutionizing various fields including machine translation, content creation, and virtual assistants.


The <a href="https://github.com/burcuozek/LLMrepo/blob/main/LLM.ipynb">LLM.ipynb</a> file serves as an introduction to the fundamentals of LLM, demonstrating how to customize and apply it in different contexts using Hugging Face. The document offers insights into selecting appropriate models and tokenizers, providing detailed explanations of their configurations.

Projects are follows: 
- Summarization
- Sentiment analysis
- Zero-shot classification
- Few-shot learning


The <a href="https://github.com/burcuozek/LLMrepo/blob/main/Rag_Tutorial.ipynb">Rag_Tutorial.ipynb</a> file includes the adaptation of RAG Retrieval Augmented Generation to LLM. It talks about the key components. It uses <a href="https://huggingface.co/datasets/databricks/databricks-dolly-15k ">databricks-dolly-15k dataset</a>.


[RAG_LLM_QuestionAnswering_DocumentPDF.ipynb](https://github.com/burcuozek/LLMrepo/blob/main/RAG_LLM_QuestionAnswering_DocumentPDF.ipynb) file presents a question-answering system utilizing Large Language Models (LLM). You can upload any research article, and the algorithm will provide answers based on the relevant context.


