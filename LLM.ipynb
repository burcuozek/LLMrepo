{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d60957bb-17c0-44f8-ab51-8ccbcc542b7c",
   "metadata": {},
   "source": [
    "# Large language models (LLM) and Hugging Face"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d3dfb5-9863-4ef0-b6ce-2c2d80f8db1a",
   "metadata": {},
   "source": [
    "A large language model (LLM) is a deep learning algorithm that can perform various tasks. They can recognize, translate, predict, or generate text or other content. Additionally, they can understand protein structures, write software code, perform text classification, answer questions, and document summarization, as well as tasks like translation, chatbots, and AI assistants.\n",
    "\n",
    "Healthcare and Science: Large language models have the ability to understand proteins, molecules, DNA, and RNA. This position allows LLMs to assist in developing vaccines, finding cures for illnesses, and improving preventative care medicines. LLMs are also used as medical chatbots to perform patient intakes or basic diagnoses.\n",
    "\n",
    "Large language models use **transformer models** and are trained using massive datasets. They must be pre-trained and then fine-tuned. For more information about the transformers, you can check my [link](https://github.com/burcuozek/Transformersrepo/blob/main/TransformersHuggingFace.ipynb).\n",
    "\n",
    "Basically, transformers consist of an **encoder and a decoder with self-attention mechanisms**. Self-attention enables the transformer model to consider different parts of the sequence or the entire context of a sentence to generate predictions.\n",
    "\n",
    "The main components are: \n",
    "- Embedding layer (captures the semantic and syntactic meaning of the input, enabling the model to understand context).\n",
    "- Feedforward layer (helps to discern the user's intent from the text input).\n",
    "- Attention mechanism (enables the model to interpret input sequences effectively).\n",
    "\n",
    "\n",
    "In this project, we will see the following applications of LLM:\n",
    "1. Summarization\n",
    "2. Sentiment analysis\n",
    "3. Zero-shot classification\n",
    "4. Few-shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f703f7c5-716f-4856-9d4f-1deda74157b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install sacremoses==0.0.53\n",
    "# !pip install -U accelerate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b864b4b-3f96-43a0-bd6f-8189ecfaf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e1299e-c391-45b2-9d89-c1ab7e7bb51e",
   "metadata": {},
   "source": [
    "# 1 - Summarization\n",
    "We will use  [xsum](https://huggingface.co/datasets/EdinburghNLP/xsum) dataset, which provides a set of BBC articles and summaries.\n",
    "\n",
    "As a model, we will use [t5-small](https://huggingface.co/t5-small) model, which is an encoder-decoder model created by Google."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9d872d7-e591-4335-9871-2d64232a44c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32303769-aafc-46b3-bb2b-0f091898a97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burcuozek/opt/anaconda3/envs/LLM/lib/python3.8/site-packages/datasets/load.py:1429: FutureWarning: The repository for xsum contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xsum\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45c0051c631c4e39b3f425a2d187e59c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b067b16713fd4237afd1147e9522ea57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/6.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c438a667aadb46099908e77710437053",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b591793bbe764b7489d3b1dff5c0ce26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/1.00M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd15b24a54b24c5084b5b2cc73a8f1c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/204045 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed471bb71c67412e89a8485f04548446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/11332 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa626f1f58884505a37857feff2ac03c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/11334 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 204045\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11332\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['document', 'summary', 'id'],\n",
       "        num_rows: 11334\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xsum_dataset = load_dataset(\n",
    "    \"xsum\", version=\"1.2.0\", cache_dir=\"../working/cache/\"\n",
    ")  # Note: We specify cache_dir to use predownloaded data.\n",
    "xsum_dataset  # The printed representation of this object shows the `num_rows` of each dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdeabeab-f2ee-4928-9ffc-e4fbec9b1df4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>summary</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>35232142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>40143035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>35951548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>36266422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>38826984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>34540833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>20836172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>35932467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>40758845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>30358490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            document  \\\n",
       "0  The full cost of damage in Newton Stewart, one...   \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Ferrari appeared in a position to challenge un...   \n",
       "3  John Edward Bates, formerly of Spalding, Linco...   \n",
       "4  Patients and staff were evacuated from Cerahpa...   \n",
       "5  Simone Favaro got the crucial try with the las...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  Belgian cyclist Demoitie died after a collisio...   \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...   \n",
       "9  The crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary        id  \n",
       "0  Clean-up operations are continuing across the ...  35232142  \n",
       "1  Two tourist buses have been destroyed by fire ...  40143035  \n",
       "2  Lewis Hamilton stormed to pole position at the...  35951548  \n",
       "3  A former Lincolnshire Police officer carried o...  36266422  \n",
       "4  An armed man who locked himself into a room at...  38826984  \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...  34540833  \n",
       "6  A man with links to a car that was involved in...  20836172  \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...  35932467  \n",
       "8  Manchester City midfielder Ilkay Gundogan says...  40758845  \n",
       "9  A jogger has been hit by an unmarked police ca...  30358490  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xsum_sample = xsum_dataset[\"train\"].select(range(10))\n",
    "display(xsum_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241bcf34-635b-47b0-b975-62a8a02279bd",
   "metadata": {},
   "source": [
    "## How to use Hugging Face pipeline tool?\n",
    "We will the Hugging Face pipeline tool to load a pre-trained model. It has the following inputs:\n",
    "\n",
    "- task: specifies the primary task.\n",
    "- model: defines the pre-trained model from the Hugging Face Hub.\n",
    "- min_length, max_length: determines the lengths of the generated summaries.\n",
    "- truncation: fixes the limits on the length of input sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9d89883-08bc-4d65-a818-9b934a53ff73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc2b278ba1445eebb4e119c42cf69d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90172dcab874f5b96d645ea4e25df86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c9d80c5ac3483893fd3b4874dba483",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6682dd23afc24d729f2b4f18a4c4680d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6109b7c06778412a9f9a1b33d4b42896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fef9883dfa40e8a398e2dcb8325981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c74208e1b8435f84f8a024cec9bd22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=40,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": \"../working/cache/\"},\n",
    ")  # Note: We specify cache_dir to use predownloaded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c36874d9-d164-41c9-9111-881096ee0a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . a flood alert remains in place across the'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Apply to 1 article\n",
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "548d6d7f-7a1a-4a4c-a288-558611108373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply to a batch of articles\n",
    "results = summarizer(xsum_sample[\"document\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e0a41ed-50c1-4e90-8512-383e35bd06e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>generated_summary</th>\n",
       "      <th>summary</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "      <td>Clean-up operations are continuing across the ...</td>\n",
       "      <td>The full cost of damage in Newton Stewart, one...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "      <td>Two tourist buses have been destroyed by fire ...</td>\n",
       "      <td>A fire alarm went off at the Holiday Inn in Ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sebastian Vettel will start third ahead of tea...</td>\n",
       "      <td>Lewis Hamilton stormed to pole position at the...</td>\n",
       "      <td>Ferrari appeared in a position to challenge un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "      <td>A former Lincolnshire Police officer carried o...</td>\n",
       "      <td>John Edward Bates, formerly of Spalding, Linco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving psychiatric treatment at the c...</td>\n",
       "      <td>An armed man who locked himself into a room at...</td>\n",
       "      <td>Patients and staff were evacuated from Cerahpa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "      <td>Defending Pro12 champions Glasgow Warriors bag...</td>\n",
       "      <td>Simone Favaro got the crucial try with the las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "      <td>A man with links to a car that was involved in...</td>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "      <td>Welsh cyclist Luke Rowe says changes to the sp...</td>\n",
       "      <td>Belgian cyclist Demoitie died after a collisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan will not be fit for the start of the ...</td>\n",
       "      <td>Manchester City midfielder Ilkay Gundogan says...</td>\n",
       "      <td>Gundogan, 26, told BBC Sport he \"can see the f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "      <td>A jogger has been hit by an unmarked police ca...</td>\n",
       "      <td>The crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   generated_summary  \\\n",
       "0  the full cost of damage in Newton Stewart is s...   \n",
       "1  a fire alarm went off at the Holiday Inn in Ho...   \n",
       "2  Sebastian Vettel will start third ahead of tea...   \n",
       "3  the 67-year-old is accused of committing the o...   \n",
       "4  a man receiving psychiatric treatment at the c...   \n",
       "5  Gregor Townsend gave a debut to powerhouse win...   \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...   \n",
       "7  the 25-year-old was hit by a motorbike during ...   \n",
       "8  gundogan will not be fit for the start of the ...   \n",
       "9  the crash happened about 07:20 GMT at the junc...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  Clean-up operations are continuing across the ...   \n",
       "1  Two tourist buses have been destroyed by fire ...   \n",
       "2  Lewis Hamilton stormed to pole position at the...   \n",
       "3  A former Lincolnshire Police officer carried o...   \n",
       "4  An armed man who locked himself into a room at...   \n",
       "5  Defending Pro12 champions Glasgow Warriors bag...   \n",
       "6  A man with links to a car that was involved in...   \n",
       "7  Welsh cyclist Luke Rowe says changes to the sp...   \n",
       "8  Manchester City midfielder Ilkay Gundogan says...   \n",
       "9  A jogger has been hit by an unmarked police ca...   \n",
       "\n",
       "                                            document  \n",
       "0  The full cost of damage in Newton Stewart, one...  \n",
       "1  A fire alarm went off at the Holiday Inn in Ho...  \n",
       "2  Ferrari appeared in a position to challenge un...  \n",
       "3  John Edward Bates, formerly of Spalding, Linco...  \n",
       "4  Patients and staff were evacuated from Cerahpa...  \n",
       "5  Simone Favaro got the crucial try with the las...  \n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...  \n",
       "7  Belgian cyclist Demoitie died after a collisio...  \n",
       "8  Gundogan, 26, told BBC Sport he \"can see the f...  \n",
       "9  The crash happened about 07:20 GMT at the junc...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display the generated summary side-by-side with the reference summary and original document.\n",
    "# We use Pandas to join the inputs and outputs together in a nice format.\n",
    "import pandas as pd\n",
    "\n",
    "display(\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"summary_text\": \"generated_summary\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(xsum_sample))[\n",
    "        [\"generated_summary\", \"summary\", \"document\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea936e5d-0351-4552-80a9-546986f28be9",
   "metadata": {},
   "source": [
    "# 2- Sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae3fe3-4235-4d3a-a3fb-eb5d7712a700",
   "metadata": {},
   "source": [
    "We will use [poem sentiment](https://huggingface.co/datasets/poem_sentiment) dataset, which provides lines from poems tagged with sentiments negative (0), positive (1), no_impact (2), or mixed (3).\n",
    "\n",
    "We will use [fine-tuned version of BERT](https://huggingface.co/nickwong64/bert-base-uncased-poems-sentiment) which is an encoder-only model from Google usable for 11+ tasks such as sentiment analysis and entity recognition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "67b28552-28ce-427a-b93e-8a7930f44d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burcuozek/opt/anaconda3/envs/LLM/lib/python3.8/site-packages/datasets/load.py:1429: FutureWarning: The repository for poem_sentiment contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/poem_sentiment\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "929ddf197c69481396c6cedaaa35392a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/3.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8bc8d0a8fd64501b4cedb9bb6b69eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/2.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55b415016a2b45ecb489eec2eff34c68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/5.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b603295f67ad4c6cb99766cd1b19eded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/19.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c520455802bf4376b57d127adc813cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.51k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23ea9bb89f6b4fbf8858e6d151d4fe18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/2.44k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "275c894ab1894008b688c6eb35cfe95f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/892 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7571e1d6212446eb23311ad9c092854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/105 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1feec4d5ab12420396d8ecd53addadb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/104 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>verse_text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>the red sword sealed their vows!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>and very venus of a pipe.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>who the man, who, called a brother.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>and so on. then a worthless gaud or two,</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>to hide the orb of truth--and every throne</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                         verse_text  label\n",
       "0   0  with pale blue berries. in these peaceful shad...      1\n",
       "1   1                it flows so long as falls the rain,      2\n",
       "2   2                 and that is why, the lonesome day,      0\n",
       "3   3  when i peruse the conquered fame of heroes, an...      3\n",
       "4   4            of inward strife for truth and liberty.      3\n",
       "5   5                   the red sword sealed their vows!      3\n",
       "6   6                          and very venus of a pipe.      2\n",
       "7   7                who the man, who, called a brother.      2\n",
       "8   8           and so on. then a worthless gaud or two,      0\n",
       "9   9         to hide the orb of truth--and every throne      2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "poem_dataset = load_dataset(\n",
    "    \"poem_sentiment\", version=\"1.0.0\", cache_dir=\"../working/cache/\"\n",
    ")\n",
    "poem_sample = poem_dataset[\"train\"].select(range(10))\n",
    "display(poem_sample.to_pandas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d48081c7-13c5-4e2e-9a67-ee36d02a3c59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b46e6ece1f412499629dd6f9635bae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/923 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f20e26a3a804407b507b6f6368b3d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/923 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45997c64c1c9462482fa902176fdaaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01823d58ac4a4aabb4f7902032f364e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/348 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a3cce1cef846b4add7d58eeadcf128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42902c9268a47fc8aa78dd458f6bbe1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c9572687474cea93feeddc59cc75e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"nickwong64/bert-base-uncased-poems-sentiment\",\n",
    "    model_kwargs={\"cache_dir\": \"../working/cache/\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb45598-f795-45ac-9da8-4014b35a36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = sentiment_classifier(poem_sample[\"verse_text\"])\n",
    "# Display the predicted sentiment side-by-side with the ground-truth label and original text.\n",
    "# The score indicates the model's confidence in its prediction.\n",
    "\n",
    "# Join predictions with ground-truth data\n",
    "joined_data = (\n",
    "    pd.DataFrame.from_dict(results)\n",
    "    .rename({\"label\": \"predicted_label\"}, axis=1)\n",
    "    .join(pd.DataFrame.from_dict(poem_sample).rename({\"label\": \"true_label\"}, axis=1))\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7450ae2-c239-4798-8001-488ce2837a41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>true_label</th>\n",
       "      <th>score</th>\n",
       "      <th>verse_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.996594</td>\n",
       "      <td>with pale blue berries. in these peaceful shad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_impact</td>\n",
       "      <td>no_impact</td>\n",
       "      <td>0.998741</td>\n",
       "      <td>it flows so long as falls the rain,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.995966</td>\n",
       "      <td>and that is why, the lonesome day,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mixed</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.968735</td>\n",
       "      <td>when i peruse the conquered fame of heroes, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mixed</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.975967</td>\n",
       "      <td>of inward strife for truth and liberty.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mixed</td>\n",
       "      <td>mixed</td>\n",
       "      <td>0.966580</td>\n",
       "      <td>the red sword sealed their vows!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>no_impact</td>\n",
       "      <td>no_impact</td>\n",
       "      <td>0.998639</td>\n",
       "      <td>and very venus of a pipe.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>no_impact</td>\n",
       "      <td>no_impact</td>\n",
       "      <td>0.998611</td>\n",
       "      <td>who the man, who, called a brother.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>negative</td>\n",
       "      <td>negative</td>\n",
       "      <td>0.996557</td>\n",
       "      <td>and so on. then a worthless gaud or two,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>no_impact</td>\n",
       "      <td>no_impact</td>\n",
       "      <td>0.998519</td>\n",
       "      <td>to hide the orb of truth--and every throne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  predicted_label true_label     score  \\\n",
       "0        positive   positive  0.996594   \n",
       "1       no_impact  no_impact  0.998741   \n",
       "2        negative   negative  0.995966   \n",
       "3           mixed      mixed  0.968735   \n",
       "4           mixed      mixed  0.975967   \n",
       "5           mixed      mixed  0.966580   \n",
       "6       no_impact  no_impact  0.998639   \n",
       "7       no_impact  no_impact  0.998611   \n",
       "8        negative   negative  0.996557   \n",
       "9       no_impact  no_impact  0.998519   \n",
       "\n",
       "                                          verse_text  \n",
       "0  with pale blue berries. in these peaceful shad...  \n",
       "1                it flows so long as falls the rain,  \n",
       "2                 and that is why, the lonesome day,  \n",
       "3  when i peruse the conquered fame of heroes, an...  \n",
       "4            of inward strife for truth and liberty.  \n",
       "5                   the red sword sealed their vows!  \n",
       "6                          and very venus of a pipe.  \n",
       "7                who the man, who, called a brother.  \n",
       "8           and so on. then a worthless gaud or two,  \n",
       "9         to hide the orb of truth--and every throne  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Change label indices to text labels\n",
    "sentiment_labels = {0: \"negative\", 1: \"positive\", 2: \"no_impact\", 3: \"mixed\"}\n",
    "joined_data = joined_data.replace({\"true_label\": sentiment_labels})\n",
    "\n",
    "display(joined_data[[\"predicted_label\", \"true_label\", \"score\", \"verse_text\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a3564d-e385-40fe-92e9-387942e95026",
   "metadata": {},
   "source": [
    "# 3- Zero-shot classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b29299a-af33-4dca-b7b8-f4a6a6d36be5",
   "metadata": {},
   "source": [
    "Zero-shot classification (or zero-shot learning) is the task of classifying a piece of text into one of a few given categories or labels, **without having explicitly trained the model to predict those categories beforehand**. \n",
    "\n",
    "We will use the [xsum](https://huggingface.co/datasets/EdinburghNLP/xsum) dataset. We aim to label news articles under a few categories.\n",
    "\n",
    "We will use [nli-deberta-v3-small model](https://huggingface.co/cross-encoder/nli-deberta-v3-small), which is a fine-tuned version of the DeBERTa model (developed by Microsoft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43094544-b35c-4586-9512-193c2ae15f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a939531-5555-4f92-9023-51434b2c9660",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/burcuozek/opt/anaconda3/envs/LLM/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "zero_shot_pipeline = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"cross-encoder/nli-deberta-v3-small\",\n",
    "    model_kwargs={\"cache_dir\": \"../working/cache/\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "35b3c0e0-c34a-4cd1-b19b-436ae12fef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_article(article: str) -> None:\n",
    "    \"\"\"\n",
    "    This helper function defines the categories (labels) which the model must use to label articles.\n",
    "    Note that our model was NOT fine-tuned to use these specific labels,\n",
    "    but it \"knows\" what the labels mean from its more general training.\n",
    "\n",
    "    This function then prints out the predicted labels alongside their confidence scores.\n",
    "    \"\"\"\n",
    "    results = zero_shot_pipeline(\n",
    "        article,\n",
    "        candidate_labels=[\n",
    "            \"politics\",\n",
    "            \"finance\",\n",
    "            \"sports\",\n",
    "            \"science and technology\",\n",
    "            \"pop culture\",\n",
    "            \"breaking news\",\n",
    "        ],\n",
    "    )\n",
    "    # Print the results nicely\n",
    "    del results[\"sequence\"]\n",
    "    display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "41fe1910-9bee-4831-bdf2-18d0df196c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labels</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>science and technology</td>\n",
       "      <td>0.435002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking news</td>\n",
       "      <td>0.158277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pop culture</td>\n",
       "      <td>0.142483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>0.103507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>finance</td>\n",
       "      <td>0.083671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>politics</td>\n",
       "      <td>0.077060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   labels    scores\n",
       "0  science and technology  0.435002\n",
       "1           breaking news  0.158277\n",
       "2             pop culture  0.142483\n",
       "3                  sports  0.103507\n",
       "4                 finance  0.083671\n",
       "5                politics  0.077060"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorize_article(\n",
    "    \"\"\"\n",
    "The AI Doctor Is In. Here's How ChatGPT May Pave a New Era of Self-Diagnosis\n",
    "The chatbot is more than fun to use: It may be the new health assistant for those who need it most in 2024 and beyond.\n",
    "Katie Sarvela was sitting in her bedroom in Nikiksi, Alaska, on top of a moose-and-bear-themed bedspread, when she entered some of her earliest symptoms into ChatGPT. \n",
    "\n",
    "The ones she remembers describing to the chatbot include half of her face feeling like it's on fire, then sometimes being numb, her skin feeling wet when it's not wet and night blindness. \n",
    "\n",
    "ChatGPT's synopsis? \n",
    "\n",
    "\"Of course it gave me the 'I'm not a doctor, I can't diagnose you,'\" Sarvela said. But then: multiple sclerosis. An autoimmune disease that attacks the central nervous system. \n",
    "Now 32, Sarvela started experiencing MS symptoms when she was in her early 20s. She gradually came to suspect it was MS, but she still needed another MRI and lumbar puncture to confirm what she and her doctor suspected. While it wasn't a diagnosis, the way ChatGPT jumped to the right conclusion amazed her and her neurologist, according to Sarvela. \n",
    "\n",
    "\n",
    "ChatGPT is an AI-powered chatbot that scrapes the internet for information and then organizes it based on which questions you ask, all served up in a conversational tone. It set off a profusion of generative AI tools throughout 2023, and the version based on the GPT-3.5 large language model is available to everyone for free. The way it can quickly synthesize information and personalize results raises the precedent set by \"Dr. Google,\" the researcher's term describing the act of people looking up their symptoms online before they see a doctor. More often we call it \"self-diagnosing.\" \n",
    "\n",
    "For people like Sarvela, who've lived for years with mysterious symptoms before getting a proper diagnosis, having a more personalized search to bounce ideas off of may help save precious time in a health care system where long wait times, medical gaslighting, potential biases in care, and communication gaps between doctor and patient lead to years of frustration. \n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769cdf9b-b868-4c9b-bec3-e1d59b3e5885",
   "metadata": {},
   "source": [
    "# 4- Few-shot learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fa3cdf-bbdb-4ba5-b831-8e9ad148e192",
   "metadata": {},
   "source": [
    "In few-shot learning tasks, you give the model an instruction, a few query-response examples of how to follow that instruction, and then a new query. \n",
    "\n",
    "Our aim is to do sentiment analysis. But few-shot learning can be applied to many tasks. In these examples, we will see how few-shot learning allows us to specify custom labels, whereas the previous model was tuned for a specific set of labels.\n",
    "\n",
    "We will use some tweet examples as a dataset. \n",
    "We will use  [gpt-neo-1.3B](https://huggingface.co/EleutherAI/gpt-neo-1.3B) model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e4b5bee-c32a-4a76-90cd-d0d2ff842509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48b41aa1e6549b286aa49a21bbe5449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc43484ffe65456289051b449585e423",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee784224954b421884f9ea35ad472084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce0cf69a7894eb9b6250c0cd3d3385d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcff5b610c7d406c8950f02885cdd7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b9880c9f24f421fbcdf41c8cf34e491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff28b95c90e944be8a8e32fdb2e7cf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We will limit the response length for our few-shot learning tasks.\n",
    "few_shot_pipeline = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=\"EleutherAI/gpt-neo-1.3B\",\n",
    "    max_new_tokens=10,\n",
    "    model_kwargs={\"cache_dir\": \"../working/cache/\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b864b66-9848-444c-beeb-56448b67305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tip: In the few-shot prompts below, we separate the examples with a special token \"###\" \n",
    "# and use the same token to encourage the LLM to end its output after answering the query.\n",
    "# We will tell the pipeline to use that special token as the end-of-sequence (EOS) token below.\n",
    "\n",
    "# Get the token ID for \"###\", which we will use as the EOS token below.\n",
    "eos_token_id = few_shot_pipeline.tokenizer.encode(\"###\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e9a2a7a0-88a1-4d94-bf22-ef660fc1ce8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: \"Liked, interesting\"\n",
      "[Tweet]:\n"
     ]
    }
   ],
   "source": [
    "# Without any examples, the model output is inconsistent and usually incorrect.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71229d04-14db-4373-a837-f049d8fd0580",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"This is the link to the article\"\n",
      "[Sentiment]: Neutral\n",
      "###\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: Neutral\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# With only 1 example, the model may or may not get the answer right.\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "722b68c7-db02-42b4-90f0-919de9cb4f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:21017 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For each tweet, describe its sentiment:\n",
      "\n",
      "[Tweet]: \"I hate it when my phone battery dies.\"\n",
      "[Sentiment]: Negative\n",
      "###\n",
      "[Tweet]: \"My day has been \"\n",
      "[Sentiment]: Positive\n",
      "###\n",
      "[Tweet]: \"This is the link to the article\"\n",
      "[Sentiment]: Neutral\n",
      "###\n",
      "[Tweet]: \"This new music video was incredible\"\n",
      "[Sentiment]: Positive\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "# With 1 example for each sentiment, the model is more likely to understand!\n",
    "results = few_shot_pipeline(\n",
    "    \"\"\"For each tweet, describe its sentiment:\n",
    "\n",
    "[Tweet]: \"I hate it when my phone battery dies.\"\n",
    "[Sentiment]: Negative\n",
    "###\n",
    "[Tweet]: \"My day has been \"\n",
    "[Sentiment]: Positive\n",
    "###\n",
    "[Tweet]: \"This is the link to the article\"\n",
    "[Sentiment]: Neutral\n",
    "###\n",
    "[Tweet]: \"This new music video was incredible\"\n",
    "[Sentiment]:\"\"\",\n",
    "    eos_token_id=eos_token_id,\n",
    ")\n",
    "\n",
    "print(results[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a0c39a-b416-49d4-8a59-e03dc4b02b35",
   "metadata": {},
   "source": [
    "### Prompt engineering is a new but critical technique for working with LLMs. As you use more general and powerful models, constructing good prompts becomes more critical. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1763bb43-0b87-4cb8-98a7-70a228b42a5b",
   "metadata": {},
   "source": [
    "# Details about Hugging Face\n",
    "\n",
    "- Search and sampling to generate text\n",
    "- Auto* loaders for tokenizers and models\n",
    "- Model-specific loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5159d610-214f-48dc-9c03-9cac5c3f6f61",
   "metadata": {},
   "source": [
    "## 1- Search and sampling in inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fa010-5515-4d45-9e54-06f49b432a91",
   "metadata": {},
   "source": [
    "LLMs work by predicting the next token, then the next, and so on. The goal is to generate a high-probability sequence of tokens,\n",
    "\n",
    "To do this search, LLMs use one of two main methods:\n",
    "\n",
    "1 - Search: Given the tokens generated so far, pick the next most likely token in a \"search.\"\n",
    "- Greedy search (default): Pick the single next most likely token in a greedy search.\n",
    "- Beam search: Greedy search can be extended via beam search, which searches down several sequence paths via the parameter num_beams.\n",
    "\n",
    "2 - Sampling: Given the tokens generated so far, pick the next token by sampling from the predicted distribution of tokens.\n",
    "- Top-K sampling: The parameter top_k modifies sampling by limiting it to the k most likely tokens.\n",
    "- Top-p sampling: The parameter top_p modifies sampling by limiting it to the most likely tokens up to probability mass p.\n",
    "\n",
    "\n",
    "We can choose sampling or search by **do_sample** parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa10ecbd-7506-47b0-84ae-e485aa5e951c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . a flood alert remains in place across the'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This does greedy search.\n",
    "summarizer(xsum_sample[\"document\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d144e1f0-5ea7-4344-a530-3a7eeaea962a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . a flood alert remains in place across the'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can instead do a beam search by specifying num_beams.\n",
    "# This takes longer to run, but it might find a better (more likely) sequence of text.\n",
    "summarizer(xsum_sample[\"document\"][0], num_beams=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ff21e20-eef8-422f-a056-f11b85f56194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'many businesses and householders were affected by flooding in Newton Stewart . the water breached a retaining wall, flooding many commercial properties . a flood alert remains in place across'}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, we could use sampling.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8731e6c-a9f1-4f42-9b7d-e21c2f1dabd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_text': 'the full cost of damage in Newton Stewart is still being assessed . many roads in peeblesshire remain badly affected by standing water . the water breached a retaining'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can modify sampling to be more greedy by limiting sampling to the top_k or top_p most likely next tokens.\n",
    "summarizer(xsum_sample[\"document\"][0], do_sample=True, top_k=10, top_p=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcfb7ab-3b71-4150-a51b-e15e3ff1be94",
   "metadata": {},
   "source": [
    "## 2- Auto* loaders for tokenizers and models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9b1700-e4a7-4380-9878-5831176c2d7d",
   "metadata": {},
   "source": [
    "While a **pipeline is a quick** way to set up an LLM for a given task, the slightly lower-level abstractions **model and tokenizer** permit a bit **more control** over options. Following is the way to do that:\n",
    "\n",
    "- Given input articles.\n",
    "- Tokenize them (converting to token indices).\n",
    "- Apply the model on the tokenized data to generate summaries (represented as token indices).\n",
    "- Decode the summaries into human-readable text.\n",
    "\n",
    "More information about the model and tokenizer can be found from this [link](https://huggingface.co/docs/transformers/main/en/model_doc/auto#transformers.AutoModelForSeq2SeqLM). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15e2f914-f0a1-4348-84ae-2707679694ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4e2b1972-095b-4234-9fcb-5d5016e09ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8108bbff-6c94-4801-acb8-41cf68c46e17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>summarize: The full cost of damage in Newton S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>summarize: A fire alarm went off at the Holida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>summarize: Ferrari appeared in a position to c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summarize: John Edward Bates, formerly of Spal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>summarize: Patients and staff were evacuated f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>summarize: Simone Favaro got the crucial try w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>summarize: Veronica Vanessa Chango-Alverez, 31...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>summarize: Belgian cyclist Demoitie died after...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>summarize: Gundogan, 26, told BBC Sport he \"ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>summarize: The crash happened about 07:20 GMT ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             prompts\n",
       "0  summarize: The full cost of damage in Newton S...\n",
       "1  summarize: A fire alarm went off at the Holida...\n",
       "2  summarize: Ferrari appeared in a position to c...\n",
       "3  summarize: John Edward Bates, formerly of Spal...\n",
       "4  summarize: Patients and staff were evacuated f...\n",
       "5  summarize: Simone Favaro got the crucial try w...\n",
       "6  summarize: Veronica Vanessa Chango-Alverez, 31...\n",
       "7  summarize: Belgian cyclist Demoitie died after...\n",
       "8  summarize: Gundogan, 26, told BBC Sport he \"ca...\n",
       "9  summarize: The crash happened about 07:20 GMT ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:\n",
      "tensor([[21603,    10,    37,  ...,     0,     0,     0],\n",
      "        [21603,    10,    71,  ...,     0,     0,     0],\n",
      "        [21603,    10, 21945,  ..., 18002,    21,     1],\n",
      "        ...,\n",
      "        [21603,    10, 21768,  ...,     0,     0,     0],\n",
      "        [21603,    10,  9982,  ...,     0,     0,     0],\n",
      "        [21603,    10,    37,  ...,     0,     0,     0]])\n",
      "attention_mask:\n",
      "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0],\n",
      "        [1, 1, 1,  ..., 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "# For summarization, T5-small expects a prefix \"summarize: \", so we prepend that to each article as a prompt.\n",
    "articles = list(map(lambda article: \"summarize: \" + article, xsum_sample[\"document\"]))\n",
    "display(pd.DataFrame(articles, columns=[\"prompts\"]))\n",
    "# Tokenize the input\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "print(\"input_ids:\")\n",
    "print(inputs[\"input_ids\"])\n",
    "print(\"attention_mask:\")\n",
    "print(inputs[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9be248e2-d776-4b6d-b288-560984859a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     8,   423,   583,    13,  1783,    16, 20126, 16496,    19,\n",
      "           341,   271, 14841,     3,     5,   186,  7540,    16,   158,    15,\n",
      "          2296,     7,  5718,  2367, 14621,  4161,    57,  4125,   387,     3,\n",
      "             5,     3,     9,  8347,  5685,  3048,    16,   286,   640,     8],\n",
      "        [    0,  1472,  6196,   877,   326,    44,     8,  9108,    86,    29,\n",
      "            16,  6000,  1887,    30,  1856,     3,     5,  2554,   130,  1380,\n",
      "            12,  1175,     8,  1595,     3,     5,    80,    13,     8,   192,\n",
      "         14264,    19,    45, 13692,    63,     6,     8,   119,    45, 20576],\n",
      "        [    0,     3,   849,  2239,     7,   163, 14014,     3,    60,  8234,\n",
      "           232,   227,     3, 19585,   643,   845,   150,  8033,    47,   787,\n",
      "            30,   213,     3,    88,   225,  2447,     3,     5,     3,   849,\n",
      "          2239,     7,   497,     3,    31,    29,    32,   964,  8033,    47],\n",
      "        [    0,     8,     3,  3708,    18,  1201,    18,  1490,    19, 11970,\n",
      "            13,     3, 25345,     8, 10883,  2319,   344,  1332, 16583,    11,\n",
      "          1797,  9975,     3,     5,     3,    88,   177,   725,    66,     8,\n",
      "          3991,     6,   379,   192, 12052,    13,    16,   221,    75,  4392],\n",
      "        [    0,     3,     9,   388,  4281,  1058,    44,     8,  5998, 16026,\n",
      "            12,  4279,  2448,    11,   717,     3,     5,     3,     9,  1021,\n",
      "          2095,  5502,    47, 29766,    26,    45,     8,  2833,     3,     5,\n",
      "             8,  5415,   639, 18905,  7012,    16, 20958,   826,   633,  6032],\n",
      "        [    0,     3, 26705,  4463,     7,   989,  1891,     3,     9,  5695,\n",
      "            12,   579,  1840,     3,  3108,  2067,  1824,   400,  1823,    23,\n",
      "            63,  2551,  1967,    32,     3,     5,     8, 14580,     7,  1891,\n",
      "           166,  3511,    13,     8,   774,    12,     3,  3108,     3,     9],\n",
      "        [    0,     3, 31873, 30003, 24187,    32,    18,   188,    40,   624,\n",
      "           457,     6, 12074,    47,  4792,    11,   430,   388,  7532,    16,\n",
      "             8,  8420,     3,     5,  2095,   241,    12,  8320, 18050,  8688,\n",
      "             6, 14141,   113,    65,  2416,    12,     8,  9835,     3,     5],\n",
      "        [    0,     8,   944,    18,  1201,    18,  1490,    47,  1560,    57,\n",
      "             3,     9,  2340, 15214,   383,     8, 21689,    18,  1326,  4911,\n",
      "           397,    51,  1964,     3,     5,     8,  1964,  2804,   190,  8390,\n",
      "          2515,   663,     3,     5,     8,  2600,    31,     7,     3, 19585],\n",
      "        [    0,  4740, 10169,   152,   845,     3,    88,    54,   217,     8,\n",
      "          8619,   689,   227,     3, 30846,     3, 22052,   342,  6476, 27588,\n",
      "             7,    16,  1882,     3,     5,     8, 13692,  4785,     8,  1412,\n",
      "           296,  4119,   227,   223,  3730,    24,  2697,   376,    91,    21],\n",
      "        [    0,     8,  8420,  2817,    81, 10668,    10,  1755, 22866,    44,\n",
      "             8, 23704,    13,     8,    71, 22367,    11, 24583,  2409,    16,\n",
      "            90,  9031,    18,   106,    18,   134,    15,     9,     6, 25223,\n",
      "             3,     5,     8,   388,     6,  9742,    16,   112,   460,     7]])\n"
     ]
    }
   ],
   "source": [
    "# Generate summaries\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "print(summary_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "257137a0-09bc-4489-8b81-a4119747addc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoded_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire alarm went off at the Holiday Inn in Hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stewards only handed reprimand after governing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving treatment at the clinic threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan says he can see the finishing line af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   decoded_summaries\n",
       "0  the full cost of damage in Newton Stewart is s...\n",
       "1  fire alarm went off at the Holiday Inn in Hope...\n",
       "2  stewards only handed reprimand after governing...\n",
       "3  the 67-year-old is accused of committing the o...\n",
       "4  a man receiving treatment at the clinic threat...\n",
       "5  Gregor Townsend gave a debut to powerhouse win...\n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...\n",
       "7  the 25-year-old was hit by a motorbike during ...\n",
       "8  gundogan says he can see the finishing line af...\n",
       "9  the crash happened about 07:20 GMT at the junc..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decode the generated summaries\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2184a0-32b8-4683-86f6-f340a020afe3",
   "metadata": {},
   "source": [
    "## 3- Model-specific tokenizer and model loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc24cebc-2481-4d97-83e2-76973e16131d",
   "metadata": {},
   "source": [
    "We can also more directly load specific tokenizer and model types, rather than relying on Auto* classes to choose the right ones for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab145b9e-0e14-4500-a10f-fc205eec6638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>decoded_summaries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the full cost of damage in Newton Stewart is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>fire alarm went off at the Holiday Inn in Hope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>stewards only handed reprimand after governing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the 67-year-old is accused of committing the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a man receiving treatment at the clinic threat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gregor Townsend gave a debut to powerhouse win...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Veronica Vanessa Chango-Alverez, 31, was kille...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the 25-year-old was hit by a motorbike during ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gundogan says he can see the finishing line af...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the crash happened about 07:20 GMT at the junc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   decoded_summaries\n",
       "0  the full cost of damage in Newton Stewart is s...\n",
       "1  fire alarm went off at the Holiday Inn in Hope...\n",
       "2  stewards only handed reprimand after governing...\n",
       "3  the 67-year-old is accused of committing the o...\n",
       "4  a man receiving treatment at the clinic threat...\n",
       "5  Gregor Townsend gave a debut to powerhouse win...\n",
       "6  Veronica Vanessa Chango-Alverez, 31, was kille...\n",
       "7  the 25-year-old was hit by a motorbike during ...\n",
       "8  gundogan says he can see the finishing line af...\n",
       "9  the crash happened about 07:20 GMT at the junc..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", cache_dir=\"../working/cache/\"\n",
    ")\n",
    "# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")\n",
    "decoded_summaries = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "\n",
    "display(pd.DataFrame(decoded_summaries, columns=[\"decoded_summaries\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e10ec-d564-4a39-9912-3eaa5466b91d",
   "metadata": {},
   "source": [
    "### Comparison of Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7ecedc-7e80-4b01-a123-5aeb50796a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PIPELINE\n",
    "\n",
    "summarizer = pipeline(\n",
    "    task=\"summarization\",\n",
    "    model=\"t5-small\",\n",
    "    min_length=20,\n",
    "    max_length=40,\n",
    "    truncation=True,\n",
    "    model_kwargs={\"cache_dir\": \"../working/cache/\"},\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff3afe-e692-4e23-85a4-49819ca68ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Auto* loaders for tokenizers and models\n",
    "\n",
    "# Load the pre-trained tokenizer and model.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59559cee-1c3a-41ce-8f8b-78d0da658b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model-specific tokenizer and model loaders\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\", cache_dir=\"../working/cache/\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    \"t5-small\", cache_dir=\"../working/cache/\"\n",
    ")\n",
    "# The tokenizer and model can then be used similarly to how we used the ones loaded by the Auto* classes.\n",
    "inputs = tokenizer(\n",
    "    articles, max_length=1024, return_tensors=\"pt\", padding=True, truncation=True\n",
    ")\n",
    "summary_ids = model.generate(\n",
    "    inputs.input_ids,\n",
    "    attention_mask=inputs.attention_mask,\n",
    "    num_beams=2,\n",
    "    min_length=0,\n",
    "    max_length=40,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a9bec7-30f0-438d-961f-c154cc60a705",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b95ab4-fb8f-46c5-80a8-be62ccdda53c",
   "metadata": {},
   "source": [
    "References: \n",
    "- https://www.kaggle.com/code/aliabdin1/llm-01-how-to-use-llms-with-hugging-face\n",
    "- https://www.elastic.co/what-is/large-language-models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
